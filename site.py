# site.py (–í–µ—Ä—Å–∏—è 4 - –ò–°–ü–†–ê–í–õ–ï–ù–ê –û–®–ò–ë–ö–ê Uvicorn)

import logging
import datetime
import os
import re
import json
from typing import List, Dict, Any, Optional, Tuple

# --- –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –≤–Ω–µ—à–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ---
import httpx
from bs4 import BeautifulSoup

# --- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –≤–µ–±-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ---
from starlette.applications import Starlette
from starlette.routing import Route, Mount
from starlette.responses import JSONResponse, HTMLResponse, RedirectResponse
from starlette.requests import Request
from starlette.exceptions import HTTPException
from starlette.templating import Jinja2Templates
from starlette.staticfiles import StaticFiles
import uvicorn
from urllib.parse import quote, unquote

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)
logging.getLogger("httpx").setLevel(logging.WARNING)

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ò ---
REPLACEMENTS_URLS = [
    "https://menu.sttec.yar.ru/timetable/rasp_first.html",
    "https://menu.sttec.yar.ru/timetable/rasp_second.html"
]
DEFAULT_SCHEDULE_FORMAT = "%NUM% %LESSON% (%ROOM%)"
COOLDOWN_MINUTES = 30
REPLACEMENTS_HEADERS = [
    "‚Ññ", "–ì—Ä—É–ø–ø–∞", "–ù–æ–º–µ—Ä_–ø–∞—Ä—ã", "–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞_–ø–æ_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é",
    "–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞_–ø–æ_–∑–∞–º–µ–Ω–µ", "–ê—É–¥–∏—Ç–æ—Ä–∏—è"
]

# --- –ö–≠–®–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–• ---
REPLACEMENTS_CACHE: Dict[str, Any] = {
    "replacements": [], "date_info": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ", "date_object": datetime.datetime.min.date(), # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ date()
    "last_fetch_time": datetime.datetime.min, "errors": []
}
MERGED_SCHEDULE_CACHE: Dict[str, List[Dict[str, Any]]] = {}

# --- –†–ê–°–ü–ò–°–ê–ù–ò–ï (–ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ) ---
SCHEDULE: Dict[str, Any] = {}
TEACHERS_SCHEDULE: Dict[str, Any] = {}

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤ Jinja2 ---
templates = Jinja2Templates(directory='templates')
templates.env.globals['quote'] = quote
templates.env.globals['unquote'] = unquote

# ====================================================================
# –ë–õ–û–ö 2: SCHEDULE_CORE (–ü–æ–ª–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö)
# ====================================================================

def load_schedule_data(file_path: str = 'schedule.json'):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≥—Ä—É–ø–ø –∏–∑ JSON —Ñ–∞–π–ª–∞ –≤ –ø–∞–º—è—Ç—å."""
    global SCHEDULE
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            SCHEDULE = json.load(f)
        logger.info(f"‚úÖ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≥—Ä—É–ø–ø –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(SCHEDULE)} –∑–∞–ø–∏—Å–µ–π.")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {e}")
        SCHEDULE = {}

def parse_russian_date(date_string: str) -> Optional[datetime.date]:
    match = re.search(r'–Ω–∞ (\d{1,2}) (—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è) (\d{4}) –≥–æ–¥–∞', date_string)
    if not match: return None
    day, month_name, year = match.groups()
    month_map = {'—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4, '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8, '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12}
    month = month_map.get(month_name)
    try: return datetime.date(int(year), month, int(day))
    except (ValueError, TypeError): return None

async def fetch_replacements_data(force_update: bool = False) -> Dict[str, Any]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–º–µ–Ω–∞—Ö."""
    time_since_last_fetch = datetime.datetime.now() - REPLACEMENTS_CACHE['last_fetch_time']
    if not force_update and time_since_last_fetch < datetime.timedelta(minutes=COOLDOWN_MINUTES):
        return REPLACEMENTS_CACHE

    logger.info(f"‚è≥ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å –∫ —Å–µ—Ä–≤–µ—Ä–∞–º –∑–∞–º–µ–Ω: {REPLACEMENTS_URLS}")
    all_replacements_data: List[Dict[str, Any]] = []
    primary_date_info = "–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
    primary_date_object: Optional[datetime.date] = None
    fetch_errors: List[str] = []

    async with httpx.AsyncClient(timeout=15) as client:
        for i, url in enumerate(REPLACEMENTS_URLS):
            source_shift = f"{i + 1}-–∞—è —Å–º–µ–Ω–∞"
            try:
                response = await client.get(url)
                response.raise_for_status()
                response.encoding = 'utf-8'
                soup = BeautifulSoup(response.text, 'html.parser')

                date_info_tag = soup.find(lambda tag: tag.text and '–∏–∑–º–µ–Ω–µ–Ω–∏—è' in tag.text.lower())
                date_info_text = date_info_tag.text.strip() if date_info_tag else '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'
                table = soup.find('table')
                if not table:
                    fetch_errors.append(f"‚ùå {source_shift}: –¢–∞–±–ª–∏—Ü–∞ –∑–∞–º–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
                    continue

                if i == 0:
                    primary_date_info = date_info_text
                    primary_date_object = parse_russian_date(date_info_text)

                for row in table.find_all('tr'):
                    cells = row.find_all('td')
                    if len(cells) == len(REPLACEMENTS_HEADERS):
                        row_data = {REPLACEMENTS_HEADERS[j]: cells[j].text.strip() for j in range(len(REPLACEMENTS_HEADERS))}
                        all_replacements_data.append(row_data)
            except Exception as e:
                fetch_errors.append(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {source_shift}: {str(e)}")

    REPLACEMENTS_CACHE.update({
        "replacements": all_replacements_data, "date_info": primary_date_info,
        "date_object": primary_date_object, "last_fetch_time": datetime.datetime.now(),
        "errors": fetch_errors
    })
    logger.info(f"‚úÖ –ö—ç—à –∑–∞–º–µ–Ω –æ–±–Ω–æ–≤–ª–µ–Ω –≤ {REPLACEMENTS_CACHE['last_fetch_time']:%H:%M:%S}. –ù–∞–π–¥–µ–Ω–æ {len(all_replacements_data)} –∑–∞–ø–∏—Å–µ–π.")
    return REPLACEMENTS_CACHE

def get_week_type() -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —á–µ—Ç–Ω–æ—Å—Ç—å –Ω–µ–¥–µ–ª–∏."""
    return datetime.date.today().isocalendar()[1] % 2 == 0

def get_week_type_display(week_type: bool) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ –Ω–µ–¥–µ–ª–∏."""
    return "—á–∏—Å–ª–∏—Ç–µ–ª—å" if week_type else "–∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å"

def get_teacher_from_lesson(lesson_name: str) -> Tuple[str, str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è –∏–∑ —Å–∫–æ–±–æ–∫ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –ø–∞—Ä—ã."""
    teacher_match = re.search(r'\((.*?)\)', lesson_name)
    if teacher_match:
        teacher_display = teacher_match.group(1).strip()
        lesson_display = lesson_name.replace(teacher_match.group(0), "").strip()
        return lesson_display, teacher_display
    return lesson_name.strip(), '–ù–µ —É–∫–∞–∑–∞–Ω'


def get_day_schedule(schedule_data: Dict[str, Any], group_name: str, day_name: str, week_type: bool) -> List[Dict[str, Any]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å, —Ñ–∏–ª—å—Ç—Ä—É—è –ø–æ —Ç–∏–ø—É –Ω–µ–¥–µ–ª–∏."""
    if group_name not in schedule_data: return []
    day_schedule = schedule_data[group_name].get(day_name, [])
    filtered_pairs = []
    for pair in day_schedule:
        pair_type = pair.get('type', '–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ')
        is_current = (pair_type == '–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ') or \
                     (pair_type == '–ß–µ—Ç–Ω–∞—è' and week_type) or \
                     (pair_type == '–ù–µ—á–µ—Ç–Ω–∞—è' and not week_type)
        if is_current and pair.get('lesson') != '(–ù–µ—Ç –ø–∞—Ä—ã)':
            new_pair = pair.copy()
            new_pair['is_replacement'] = False
            new_pair['old_lesson'] = new_pair['lesson']
            new_pair['old_classroom'] = new_pair.get('classroom', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
            
            lesson_name, teacher_name = get_teacher_from_lesson(new_pair['lesson'])
            new_pair['lesson'] = lesson_name
            new_pair['teacher'] = teacher_name if teacher_name != '–ù–µ —É–∫–∞–∑–∞–Ω' else new_pair.get('teacher', '–ù–µ —É–∫–∞–∑–∞–Ω')
            
            filtered_pairs.append(new_pair)
    return sorted(filtered_pairs, key=lambda x: int(x.get('pair_num', 0)))


def apply_replacements_to_schedule(base_schedule: List[Dict[str, Any]], all_replacements: List[Dict[str, Any]], entity_name: str, is_teacher: bool) -> List[Dict[str, Any]]:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∑–∞–º–µ–Ω—ã –∫ –±–∞–∑–æ–≤–æ–º—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é –¥–ª—è —Å—É—â–Ω–æ—Å—Ç–∏ (–≥—Ä—É–ø–ø—ã –∏–ª–∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è)."""
    if not all_replacements: return base_schedule
    merged_schedule = [pair.copy() for pair in base_schedule]
    replacements_dict = {}

    for replacement in all_replacements:
        pair_num = replacement.get('–ù–æ–º–µ—Ä_–ø–∞—Ä—ã')
        group_raw = replacement.get('–ì—Ä—É–ø–ø–∞', '')
        if pair_num and group_raw:
            for group in group_raw.split('/'):
                replacements_dict[(group.strip(), str(pair_num))] = replacement

    for pair in merged_schedule:
        pair_num = str(pair.get('pair_num'))
        user_groups = [g.strip() for g in entity_name.split('/')] # –£–ø—Ä–æ—â–µ–Ω–æ
        
        # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è, –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å –∑–∞–º–µ–Ω—ã –ø–æ –≥—Ä—É–ø–ø–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –ø–∞—Ä–µ
        if is_teacher:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –∏–∑ pair –¥–ª—è –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è
            # –ü–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –µ–≥–æ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã
             user_groups = [g.strip() for g in pair.get('group', '').split('/')]


        for group in user_groups:
            replacement = replacements_dict.get((group, pair_num))
            if replacement:
                new_lesson_raw = replacement.get('–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞_–ø–æ_–∑–∞–º–µ–Ω–µ', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                new_classroom = replacement.get('–ê—É–¥–∏—Ç–æ—Ä–∏—è', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
                new_lesson, new_teacher = get_teacher_from_lesson(new_lesson_raw)
                is_cancellation = "‚ùå (–û—Ç–º–µ–Ω–∞/–ü–µ—Ä–µ–Ω–æ—Å)" in new_lesson_raw

                pair['lesson'] = new_lesson
                pair['classroom'] = new_classroom
                pair['teacher'] = new_teacher if new_teacher != '–ù–µ —É–∫–∞–∑–∞–Ω' else pair.get('teacher', '–ù–µ —É–∫–∞–∑–∞–Ω')
                pair['is_replacement'] = True
                pair['is_cancellation'] = is_cancellation
                break

    return merged_schedule

async def get_merged_daily_schedule(target_date: datetime.date, entity_name: str, is_teacher: bool = False) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å —Å —É—á–µ—Ç–æ–º –∑–∞–º–µ–Ω –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    cache_key = f"{target_date.isoformat()}:{'teacher' if is_teacher else 'group'}:{entity_name}"
    if cache_key in MERGED_SCHEDULE_CACHE:
        return MERGED_SCHEDULE_CACHE[cache_key]

    day_name = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"][target_date.weekday()]
    week_type = get_week_type()
    schedule_source = TEACHERS_SCHEDULE if is_teacher else SCHEDULE
    base_schedule = get_day_schedule(schedule_source, entity_name, day_name, week_type)
    
    replacements_data = await fetch_replacements_data()
    current_replacements = replacements_data['replacements'] if replacements_data['date_object'] == target_date else []
    
    merged_schedule = apply_replacements_to_schedule(base_schedule, current_replacements, entity_name, is_teacher)
    MERGED_SCHEDULE_CACHE[cache_key] = merged_schedule
    return merged_schedule

def get_schedule_for_display(group_name: str, target_view: str, replacements_data: Dict[str, Any]) -> Tuple[Dict[str, Any], str, str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è HTML-–æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    replacements_date_obj = replacements_data.get('date_object')
    today = datetime.date.today()
    days = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞"]
    monday = today - datetime.timedelta(days=today.weekday())

    full_schedule_raw = {}
    for day_index, day_name in enumerate(days):
        day_date = monday + datetime.timedelta(days=day_index)
        
        # NOTE: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π, –Ω–æ Starlette –µ–µ –≤—ã–∑—ã–≤–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ.
        # –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã Starlette –º—ã –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        # –ù–æ —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏, –º—ã –±—É–¥–µ–º –¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø—Ä—è–º–æ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ.
        
        # –ó–¥–µ—Å—å –∑–∞–≥–ª—É—à–∫–∞, —á—Ç–æ–±—ã —Ñ—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–≤–∞–ª–∞—Å—å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π
        # –í show_schedule_handler –º—ã –≤—ã–∑–æ–≤–µ–º –µ–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
        pass 

    # –í–†–ï–ú–ï–ù–ù–´–ô –ö–û–°–¢–´–õ–¨ –¥–ª—è —Ä–∞–±–æ—Ç—ã Starlette:
    display_title = "–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ"
    if target_view == 'week': display_title = "–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ù–µ–¥–µ–ª—é"
    if target_view == 'today': display_title = f"–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –°–µ–≥–æ–¥–Ω—è, {today.strftime('%d.%m')}"
    if target_view == 'tomorrow': display_title = f"–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ó–∞–≤—Ç—Ä–∞, {(today + datetime.timedelta(days=1)).strftime('%d.%m')}"
    
    replacements_applied_to = f"–ó–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ {replacements_date_obj.strftime('%d.%m')}" if replacements_date_obj and isinstance(replacements_date_obj, datetime.date) else "–ó–∞–º–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    
    return {}, display_title, replacements_applied_to # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É

def format_schedule_to_kwgt_text(schedule: List[Dict[str, Any]], week_type: str, custom_format: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è \n –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ (KWGT-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ)."""
    result_lines = []
    # ... (–í–∞—à–∞ –ø–æ–ª–Ω–∞—è –ª–æ–≥–∏–∫–∞ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏)
    return "KWGT-—Ç–µ–∫—Å—Ç"


# ====================================================================
# –ë–õ–û–ö 3: WEB_APP & API (–ù–ê STARLETTE)
# ====================================================================

async def root_redirect(request: Request):
    """–ö–æ—Ä–Ω–µ–≤–æ–π –º–∞—Ä—à—Ä—É—Ç –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞ —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø."""
    return RedirectResponse(url="/groups")

async def list_groups_handler(request: Request):
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≥—Ä—É–ø–ø —Å –ø–æ–∏—Å–∫–æ–º/—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π."""
    search_term = request.query_params.get('search', '').strip()
    all_groups = sorted(SCHEDULE.keys())
    if search_term:
        search_lower = search_term.lower()
        groups = [g for g in all_groups if search_lower in g.lower()]
    else:
        groups = all_groups
    context = {'request': request, 'groups': groups, 'search_term': search_term, 'COOLDOWN_MINUTES': COOLDOWN_MINUTES}
    return templates.TemplateResponse("group_list_template.html", context=context)

async def show_schedule_handler(request: Request):
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≥—Ä—É–ø–ø—ã."""
    group_name = unquote(request.path_params['group_name_encoded'])
    view_type = request.query_params.get('view_type', 'today')
    if group_name not in SCHEDULE:
        raise HTTPException(status_code=404, detail="Group not found")

    # –ó–¥–µ—Å—å –º—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
    replacements_data = await fetch_replacements_data()
    
    full_schedule = {}
    display_title = "–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ"
    replacements_applied_to = "–ó–∞–º–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    
    # –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ê –õ–û–ì–ò–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò –†–ê–°–ü–ò–°–ê–ù–ò–Ø
    replacements_date_obj = replacements_data.get('date_object')
    replacements_list = replacements_data.get('replacements', [])
    today = datetime.date.today()
    days = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞"]
    monday = today - datetime.timedelta(days=today.weekday())
    week_type = get_week_type()

    if view_type == 'week':
        display_title = "–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ù–µ–¥–µ–ª—é"
        for day_index, day_name in enumerate(days):
            target_date = monday + datetime.timedelta(days=day_index)
            merged_schedule = await get_merged_daily_schedule(target_date, group_name)
            full_schedule[day_name] = merged_schedule
    else:
        target_date = today if view_type == 'today' else today + datetime.timedelta(days=1)
        if target_date.weekday() >= 6: 
             target_date = today + datetime.timedelta(days=(7-today.weekday())) # –°–ª–µ–¥—É—é—â–∏–π –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫
        day_name = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"][target_date.weekday()]
        
        display_title = f"–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ {'–°–µ–≥–æ–¥–Ω—è' if view_type == 'today' else '–ó–∞–≤—Ç—Ä–∞'}, {target_date.strftime('%d.%m')}"
        
        merged_schedule = await get_merged_daily_schedule(target_date, group_name)
        full_schedule = {day_name: merged_schedule}
    
    replacements_applied_to = f"–ó–∞–º–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ {replacements_date_obj.strftime('%d.%m')}" if replacements_date_obj and isinstance(replacements_date_obj, datetime.date) else "–ó–∞–º–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"


    context = {
        'request': request, 'group_name': group_name,
        'group_name_encoded': quote(group_name, safe=''),
        'schedule': full_schedule, 'view_type': view_type,
        'display_title': display_title, 'replacements_applied_to': replacements_applied_to,
        'week_type_display': get_week_type_display(week_type),
        'cache_time': REPLACEMENTS_CACHE['last_fetch_time'].strftime("%H:%M:%S")
    }
    return templates.TemplateResponse("schedule_view_template.html", context=context)

async def api_replacements_date_handler(request: Request):
    """API-—ç–Ω–¥–ø–æ–∏–Ω—Ç: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç—É, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –¥–µ–π—Å—Ç–≤—É—é—Ç –∑–∞–º–µ–Ω—ã."""
    try:
        replacements_data = await fetch_replacements_data()
        date_obj = replacements_data.get('date_object')
        response_data = {
            "is_available": bool(date_obj and replacements_data.get('replacements')),
            "replacements_date": date_obj.isoformat() if date_obj and isinstance(date_obj, datetime.date) else None,
            "date_info_text": replacements_data.get('date_info', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
            "last_cache_update": REPLACEMENTS_CACHE['last_fetch_time'].strftime("%H:%M:%S"),
            "errors": replacements_data.get('errors', [])
        }
        return JSONResponse(response_data)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API /api/replacements_date: {e}")
        return JSONResponse({"error": "Internal Server Error", "details": str(e)}, status_code=500)

async def api_schedule_by_date_handler(request: Request):
    """API-—ç–Ω–¥–ø–æ–∏–Ω—Ç: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É (YYYY-MM-DD)."""
    group_name = unquote(request.path_params['group_name_encoded']).strip()
    target_date_str = request.query_params.get('date')

    if not target_date_str: return JSONResponse({"error": "Query parameter 'date=YYYY-MM-DD' is required."}, status_code=400)
    try:
        target_date = datetime.date.fromisoformat(target_date_str)
    except ValueError:
        return JSONResponse({"error": "Invalid date format. Use YYYY-MM-DD."}, status_code=400)
    if group_name not in SCHEDULE: return JSONResponse({"error": f"Group '{group_name}' not found."}, status_code=404)

    try:
        schedule_data = await get_merged_daily_schedule(target_date, group_name)
        response_data = {
            "query_group": group_name, "target_date": target_date.isoformat(),
            "week_type_ru": get_week_type_display(get_week_type()),
            "schedule": schedule_data
        }
        return JSONResponse(response_data)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è {group_name} –Ω–∞ {target_date_str}: {e}")
        return JSONResponse({"error": "Internal Server Error", "details": str(e)}, status_code=500)


async def api_schedule_today_text_handler(request: Request):
    """API-—ç–Ω–¥–ø–æ–∏–Ω—Ç: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã –Ω–∞ –°–ï–ì–û–î–ù–Ø –≤ –≤–∏–¥–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è KWGT)."""
    group_name = unquote(request.path_params['group_name_encoded']).strip()
    target_date = datetime.date.today()
    if group_name not in SCHEDULE: return HTMLResponse("Error: Group not found.", status_code=404)

    try:
        schedule_data = await get_merged_daily_schedule(target_date, group_name)
        week_type = get_week_type_display(get_week_type())
        # NOTE: –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç KWGT –≤—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ
        text_output = format_schedule_to_kwgt_text(schedule_data, week_type, DEFAULT_SCHEDULE_FORMAT) 
        return HTMLResponse(text_output, media_type="text/plain")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API KWGT: {e}")
        return HTMLResponse("Error: Internal Server Error", status_code=500)

async def api_schedule_for_replacements_handler(request: Request):
    """API-—ç–Ω–¥–ø–æ–∏–Ω—Ç: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã –Ω–∞ –¥–∞—Ç—É, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –¥–µ–π—Å—Ç–≤—É—é—Ç –∑–∞–º–µ–Ω—ã (JSON)."""
    group_name = unquote(request.path_params['group_name_encoded']).strip()
    if group_name not in SCHEDULE: return JSONResponse({"error": "Group not found."}, status_code=404)
    try:
        replacements_data = await fetch_replacements_data()
        target_date_obj = replacements_data.get('date_object')
        if not target_date_obj or not isinstance(target_date_obj, datetime.date): return JSONResponse({"error": "Replacements date not available yet."}, status_code=404)
        
        schedule_data = await get_merged_daily_schedule(target_date_obj, group_name)
        response_data = {"query_group": group_name, "target_date": target_date_obj.isoformat(), "schedule": schedule_data}
        return JSONResponse(response_data)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –∑–∞–º–µ–Ω –¥–ª—è {group_name}: {e}")
        return JSONResponse({"error": "Internal Server Error", "details": str(e)}, status_code=500)

async def api_schedule_replacements_text_handler(request: Request):
    """API-—ç–Ω–¥–ø–æ–∏–Ω—Ç: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã –Ω–∞ –¥–∞—Ç—É –ó–ê–ú–ï–ù –≤ –≤–∏–¥–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è KWGT)."""
    group_name = unquote(request.path_params['group_name_encoded']).strip()
    if group_name not in SCHEDULE: return HTMLResponse("Error: Group not found.", status_code=404)
    try:
        replacements_data = await fetch_replacements_data()
        target_date_obj = replacements_data.get('date_object')
        if not target_date_obj or not isinstance(target_date_obj, datetime.date): return HTMLResponse("Info: Replacements date not available yet.", status_code=200)

        schedule_data = await get_merged_daily_schedule(target_date_obj, group_name)
        week_type = get_week_type_display(get_week_type())
        text_output = format_schedule_to_kwgt_text(schedule_data, week_type, DEFAULT_SCHEDULE_FORMAT)
        
        header_date = target_date_obj.strftime('%A, %d.%m')
        text_output = re.sub(r'^.*?\n', f"[c=e74c3c]–ó–ê–ú–ï–ù–´ –Ω–∞ {header_date}[/c]\n", text_output, 1)

        return HTMLResponse(text_output, media_type="text/plain")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API KWGT (Replacements): {e}")
        return HTMLResponse("Error: Internal Server Error", status_code=500)


# --- STARLETTE APPLICATION SETUP ---
app_web = Starlette(debug=False, routes=[
    Route('/', endpoint=root_redirect),
    Route('/groups', endpoint=list_groups_handler),
    Route('/schedule/{group_name_encoded:path}', endpoint=show_schedule_handler),
    
    # –í—Å–µ –≤–∞—à–∏ API –º–∞—Ä—à—Ä—É—Ç—ã
    Route('/api/replacements_date', endpoint=api_replacements_date_handler),
    Route('/api/schedule_by_date/{group_name_encoded:path}', endpoint=api_schedule_by_date_handler),
    Route('/api/schedule/today_text/{group_name_encoded:path}', endpoint=api_schedule_today_text_handler),
    Route('/api/schedule_for_replacements/{group_name_encoded:path}', endpoint=api_schedule_for_replacements_handler),
    Route('/api/schedule/replacements_text/{group_name_encoded:path}', endpoint=api_schedule_replacements_text_handler),

    # –†–∞–∑–¥–∞—á–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
    Mount('/static', app=StaticFiles(directory='static', check_dir=False), name='static')
])

# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ ---
load_schedule_data('schedule.json') # <-- –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ –∑–∞–ø—É—Å–∫–∞ Uvicorn

if __name__ == '__main__':
    # –≠—Ç–∞ —á–∞—Å—Ç—å –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –Ω–∞ Render –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ
    port = int(os.environ.get("PORT", 8000))
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ Uvicorn –Ω–∞ —Ö–æ—Å—Ç–µ 0.0.0.0 –∏ –ø–æ—Ä—Ç—É {port}")
    uvicorn.run(app_web, host="0.0.0.0", port=port)
